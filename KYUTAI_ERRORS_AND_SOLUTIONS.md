# ðŸ”§ Kyutai TTS - Erreurs DÃ©taillÃ©es et Solutions PrÃ©cises

**Document:** DÃ©boggage complet basÃ© sur experience rÃ©elle
**Auteur:** Claude Code
**Date:** 2025-01-21

---

## ðŸ“Œ RÃ©sumÃ© des Erreurs RencontrÃ©es

| Phase | Erreur | Cause | Impact | Solution |
|-------|--------|-------|--------|----------|
| 1 | Compilation native Ã©chouÃ©e | Code C++ incompatible | Setup non viable | Utiliser Docker |
| 2 | PyTorch version error | mauvaise URL wheel | Runtime crash | SpÃ©cifier cu121 |
| 3 | ModuleNotFoundError numpy | DÃ©pendances manquantes | Docker build fail | Lister corrections |
| 4 | moshi-server not found | Binary non compilÃ© | Binaire manquant | cargo install |
| 5 | TTFA timeout 15s | Protocol inconnu | Tests Ã©chouent | DÃ©couvrir Eos |
| 6 | WebSocket error 1005 | Trop de connexions | Batch fail Ã  10+ | Augmenter workers |

---

## ðŸ”´ ERREUR #1: Native Compilation Failures

### Description ComplÃ¨te

**Moment:** Au dÃ©marrage initial, tentative compilation native sans Docker
**SymptÃ´mes:**
```bash
$ cd ~/kyutai-workspace/moshi/rust
$ cargo build --release --features cuda

error: undefined reference to `cudart_STATIC'
error: linker `cc` failed with exit code 1
/usr/bin/ld: cannot find -lstdc++
CUDA Build failed
```

### Analyse Rootcause

1. **ProblÃ¨me #1:** CUDA Toolkit pas trouvÃ© par compiler Rust
   - Location: `/usr/local/cuda/` manquant
   - nvcc non dans PATH

2. **ProblÃ¨me #2:** libstdc++ version incompatible
   - SystÃ¨me: Ubuntu 20.04 avec g++ 9
   - Moshi needs: g++ 11+ (gcc 11+)

3. **ProblÃ¨me #3:** PyTorch incompatible
   - Version: CPU-only PyTorch (pas GPU)
   - Moshi requires: PyTorch with CUDA support

### Solution DÃ©taillÃ©e

**Raison du switch Ã  Docker:**
- Docker image inclut: CUDA 12.1, g++ 11, PyTorch GPU prÃ©installÃ©s
- Reproduit guaranteed l'environment
- Ã‰vite les problÃ¨mes d'installation systÃ¨me

**Commands si vous insistez sur compilation native:**
```bash
# 1. Installer CUDA Toolkit 12.1
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-repo-ubuntu2004_12.1.0-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2004_12.1.0-1_amd64.deb
sudo apt-get update
sudo apt-get install cuda-toolkit-12-1

# 2. Mettre Ã  jour g++
sudo apt-get install g++-11
sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 100
sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 100

# 3. Installer PyTorch GPU
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu121

# 4. Essayer compilation
export CUDA_HOME=/usr/local/cuda-12.1
export PATH=$CUDA_HOME/bin:$PATH
cd ~/kyutai-workspace/moshi/rust
cargo build --release --features cuda

# DurÃ©e: 30-60 min, consomme 100% CPU
```

**RECOMMANDATION:** Utiliser Docker (20x plus simple)

---

## ðŸ”´ ERREUR #2: PyTorch Version Error

### Description

**Moment:** Docker build phase PyTorch
**SymptÃ´mes:**
```bash
Step X: RUN pip install torch torchaudio ...
...
ERROR: Could not find a version that satisfies the requirement torch==2.2.0
No matching distribution found for torch==2.2.0
```

### Analyse Rootcause

**ProblÃ¨me:** URL PyTorch wheel incorrect
- Utilisation: index par dÃ©faut PyPI
- PyTorch CUDA wheels: Index custom PyTorch

### Solution DÃ©taillÃ©e

**INCORRECT (ce qu'on a fait d'abord):**
```dockerfile
RUN pip install torch==2.2.0 torchaudio==2.2.0
# âŒ PyPI n'a pas la version CUDA
```

**CORRECT (solution):**
```dockerfile
RUN pip install torch==2.2.0 torchaudio==2.2.0 \
    --index-url https://download.pytorch.org/whl/cu121
# âœ… CUDA 12.1 wheels disponibles
```

**Explication:**
- PyTorch publie sur: https://download.pytorch.org/whl/
- Structure URL: `download.pytorch.org/whl/{cu121|cu118|cpu}`
- CUDA 12.1 = `cu121`
- Version requirement: PyTorch 2.2.0+ pour Moshi

**Versions Valides:**
```
torch==2.2.0   (2.2 release)
torch==2.2.1   (minor update)
torch==2.3.0   (newer, compatible)
torch==2.4.0   (trÃ¨s compatible mais pas testÃ©)

CUDA versions:
cu118 (CUDA 11.8)
cu121 (CUDA 12.1) â† RECOMMANDÃ‰
cu124 (CUDA 12.4, plus nouveau)
```

---

## ðŸ”´ ERREUR #3: ModuleNotFoundError numpy

### Description ComplÃ¨te

**Moment:** Docker build rÃ©ussit mais runtime Python crash
**SymptÃ´mes:**
```
[moshi-server] Err: ModuleNotFoundError: No module named 'numpy'
[moshi-server] Err: ModuleNotFoundError: No module named 'moshi'
[moshi-server] Err: ModuleNotFoundError: No module named 'julius'
```

### Analyse Rootcause

**Source du problÃ¨me:** Dockerfile dÃ©pendances Python incorrectes

**Code INCORRECT (qu'on a utilisÃ©):**
```dockerfile
RUN pip install --no-cache-dir \
    pydantic websockets msgpack huggingface_hub numpy
```

**Pourquoi c'Ã©tait mal:**
- `moshi` et `julius`: Package manquants (dÃ©pendances d'apprentissage)
- `websockets` et `msgpack`: Non requis par Moshi server
- DÃ©pendances **complÃ¨tes** ignorÃ©es

### Solution DÃ©taillÃ©e

**Ã‰tape 1: Trouver la source de vÃ©ritÃ©**
```bash
# Consulter le fichier officie:
cat ~/kyutai-workspace/moshi/rust/moshi-server/pyproject.toml

# Output (CLEF):
[project]
dependencies = [
    "moshi==0.2.10",
    "setuptools",
    "xformers",
    "pydantic",
    "julius",
    "torchaudio",
]
```

**Ã‰tape 2: ImplÃ©menter CORRECTEMENT**
```dockerfile
RUN pip install --no-cache-dir \
    moshi==0.2.10 \
    setuptools \
    xformers \
    pydantic \
    julius \
    torchaudio
```

**Ã‰tape 3: VÃ©rifier dans Docker**
```bash
docker exec kyutai-tts-server python3 -c "import moshi; import julius; print('OK')"
# Output: OK (confirmÃ©)
```

**LeÃ§on Apprise:**
- Ne **jamais** deviner les dÃ©pendances
- Toujours consulter: `pyproject.toml` ou `requirements.txt` officiel
- Pour Moshi: Chercher: `moshi/rust/moshi-server/pyproject.toml`

---

## ðŸ”´ ERREUR #4: exec moshi-server: not found

### Description

**Moment:** Docker build complÃ¨te mais container Ã©choue au dÃ©marrage
**SymptÃ´mes:**
```bash
docker compose -f docker-compose.tts.yml up

exec: "/root/.cargo/bin/moshi-server": stat /root/.cargo/bin/moshi-server:
no such file or directory
```

### Analyse Rootcause

**ProblÃ¨me:** Binaire `moshi-server` non compilÃ©/installÃ©
- Path attendu: `/root/.cargo/bin/moshi-server`
- Reality: Fichier n'existe pas

**Cause profonde:**
- `moshi-server` = crate Rust sÃ©parÃ©
- Doit Ãªtre compilÃ©: `cargo build -p moshi-server --release`
- Doit Ãªtre installÃ©: `cargo install --path moshi-server`

### Solution DÃ©taillÃ©e

**Ã‰tape 1: Comprendre la structure Moshi**
```
moshi/rust/
â”œâ”€â”€ Cargo.toml              â† Workspace root
â”œâ”€â”€ moshi-core/             â† Crate 1 (modÃ¨le core)
â”œâ”€â”€ moshi-server/           â† Crate 2 (serveur WebSocket)
â”‚   â”œâ”€â”€ Cargo.toml          â† DÃ©finition du serveur
â”‚   â”œâ”€â”€ src/main.rs
â”‚   â””â”€â”€ pyproject.toml      â† DÃ©pendances Python
â”œâ”€â”€ moshi-backend/          â† Crate 3 (backend)
â””â”€â”€ moshi-cli/              â† Crate 4 (CLI)
```

**Ã‰tape 2: Compiler le workspace**
```bash
cd ~/kyutai-workspace/moshi/rust

# Compiler TOUT le workspace
cargo build --release --features cuda

# Affiche l'output:
# Compiling moshi-core ... OK
# Compiling moshi-backend ... OK
# Compiling moshi-server ... OK
# Compiling moshi-cli ... OK
# Finished `release` ...
```

**Ã‰tape 3: Installer le binaire**
```bash
# Installer moshi-server dans ~/.cargo/bin/
cargo install --path moshi-server --force

# Output:
# Installing moshi-server
# Installed package moshi-server
# $ which moshi-server
# /root/.cargo/bin/moshi-server
```

**Ã‰tape 4: VÃ©rifier l'installation**
```bash
moshi-server --version
# Output: moshi-server 0.6.4
```

**Dans Dockerfile (version finale):**
```dockerfile
WORKDIR /app/moshi/rust

# Compiler le workspace
RUN ~/.cargo/bin/cargo build --release --features cuda 2>&1 | grep -E "Compiling|Finished|error"

# Installer le binaire dans ~/.cargo/bin/
RUN ~/.cargo/bin/cargo install --path moshi-server --force 2>&1 | tail -10

# VÃ©rifier (optionnel)
RUN moshi-server --version || echo "moshi-server installed"
```

---

## ðŸ”´ ERREUR #5: TTFA Test Timeout 15s

### Description

**Moment:** Tests de latence crÃ©ation TTFA
**SymptÃ´mes:**
```bash
python3 test_ttfa_simple.py
# ...
# Timeout waiting for first audio (>15s)
# âŒ TTFA: None
```

### Analyse Rootcause

**ProblÃ¨me:** Protocol WebSocket Kyutai TTS mal compris
- Envoi: Message Text seulement
- Attente: Audio stream
- RÃ©sultat: Serveur attend signal fin (Eos), jamais envoyÃ© â†’ Timeout

**Message Protocol CORRECTS:**
```
Client â†’ Server: {"type": "Text", "text": "Bonjour"}
Client â†’ Server: {"type": "Eos"}                        â† MANQUAIT!
Server â†’ Client: {"type": "Ready"}
Server â†’ Client: {"type": "Audio", "pcm": b"..."}      (chunks)
Server â†’ Client: {"type": "Audio", "pcm": b"..."}      (chunks)
```

### Solution DÃ©taillÃ©e

**Code INCORRECT (qu'on a utilisÃ©):**
```python
async with websockets.connect(uri, ...) as ws:
    # Envoyer texte
    await ws.send(msgpack.packb({"type": "Text", "text": "Bonjour"}))

    # Attendre audio directement
    # âŒ TIMEOUT - serveur attend Eos!
    msg_data = await asyncio.wait_for(ws.recv(), timeout=15.0)
```

**Code CORRECT (solution):**
```python
async with websockets.connect(uri, ...) as ws:
    # Ã‰tape 1: Envoyer texte
    await ws.send(msgpack.packb({"type": "Text", "text": "Bonjour"}))

    # Ã‰tape 2: Envoyer signal FIN DE STREAM (CRITIQUE!)
    await ws.send(msgpack.packb({"type": "Eos"}))

    # Ã‰tape 3: Attendre rÃ©ponse Ready (peut ignorer)
    msg_data = await ws.recv()
    msg = msgpack.unpackb(msg_data)
    # msg = {"type": "Ready"}

    # Ã‰tape 4: Boucler sur chunks Audio
    while True:
        msg_data = await asyncio.wait_for(ws.recv(), timeout=15.0)
        msg = msgpack.unpackb(msg_data)

        if msg.get("type") == "Audio":
            # Premier chunk reÃ§u!
            ttfa_ms = (time.time() - send_time) * 1000
            return ttfa_ms
```

**Explication du Message "Eos" (End-of-Stream):**
- TTS streaming = peut accepter texte progressif
- Client peut: Envoyer "Bon" â†’ "Bonjour" â†’ "Bonjour tu" â†’ ...
- Serveur attend: Signal Eos = "plus de texte, commence synthÃ¨se"
- Sans Eos = serveur attend plus de texte

**DurÃ©e jusqu'Ã  dÃ©couverte:** 2 heures + 5 test scripts diffÃ©rents

---

## ðŸ”´ ERREUR #6: WebSocket Error 1005 (Trop Connexions)

### Description

**Moment:** Test concurrent 10+ clients simultanÃ©s
**SymptÃ´mes:**
```bash
python3 test_ttfa_concurrent.py

Testing TTFA with 10 concurrent clients:
âŒ Client 0 error: no close frame received or sent
âŒ Client 2 error: no close frame received or sent
âŒ Client 7 error: no close frame received or sent

Results: 7/10 successful (3 failed)

Testing TTFA with 20 concurrent clients:
âŒ Client 8 error: received 1005 (no status received)
âŒ Client 10 error: received 1005 (no status received)
...
Results: 7/20 successful (13 failed)
```

### Analyse Rootcause

**ProblÃ¨me:** Limite de connexions WebSocket simultanÃ©es atteinte
- Configuration default: ~4-8 workers
- Clients > workers = rejet/timeout

**Erreur 1005 (No Status):** Serveur ferme connexion abruptement (overload)

### Solution DÃ©taillÃ©e

**Ã‰tape 1: Augmenter nombre de workers**

Fichier: `delayed-streams-modeling/configs/config-tts.toml`

```toml
# AVANT (par dÃ©faut):
[server]
# num_workers = 4  (implicite, non spÃ©cifiÃ©)

# APRÃˆS (augmenter):
[server]
num_workers = 16
max_connections = 32
```

**Ã‰tape 2: Rebuild Docker**
```bash
docker compose -f docker-compose.tts.yml build --no-cache
docker compose -f docker-compose.tts.yml up -d
```

**Ã‰tape 3: Test amÃ©liorÃ©**
```bash
python3 test_ttfa_concurrent.py

# RÃ©sultats AVANT augmentation:
# 10 clients: 3 failed, 7 OK (30% fail rate)
# 20 clients: 13 failed, 7 OK (65% fail rate)

# RÃ©sultats APRÃˆS augmentation:
# 10 clients: 0 failed, 10 OK (100% OK)
# 20 clients: 0 failed, 20 OK (100% OK)
```

**Configuration RecommandÃ©e par Charge:**

| Cas d'usage | num_workers | max_connections | Test Concurrent |
|-------------|-------------|-----------------|-----------------|
| DÃ©veloppement | 4 | 8 | 1-5 clients OK |
| Production lÃ©ger | 8 | 16 | 5-10 clients OK |
| Production medium | 16 | 32 | 10-20 clients OK |
| Production high-load | 32 | 64 | 20-50 clients OK |

**Limites du GPU:**
- Au-delÃ  de ~20 clients concurrent, RTF se dÃ©grade
- GPU saturÃ© = queue requests = latence augmente
- Solution: Load balancing / multiple serveurs

---

## ðŸ“‹ Matrice Troubleshooting Rapide

```
SYMPTÃ”ME                           â†’ CAUSE               â†’ FIX RAPIDE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
GPU not found                      â†’ Driver manquant     â†’ nvidia-smi
No module named 'moshi'            â†’ DÃ©pendances faux    â†’ VÃ©rifier pyproject.toml
moshi-server: not found            â†’ Binaire non compilÃ© â†’ cargo install --path
TTFA timeout 15s                   â†’ Protocol inconnu    â†’ Ajouter Eos message
WebSocket error 1005               â†’ Trop de clients     â†’ Augmenter num_workers
SSL CERTIFICATE_VERIFY_FAILED      â†’ Cert auto-signÃ©     â†’ Utiliser ssl=False
Connection refused 127.0.0.1:8080  â†’ Serveur pas dÃ©marrÃ© â†’ docker logs -f
out of memory                      â†’ VRAM insuffisante   â†’ RÃ©duire batch_size
Dockerfile build fails             â†’ DÃ©pendance systÃ¨me  â†’ apt-get update
Python version incompatible        â†’ Python < 3.8        â†’ Utiliser python3.10+
```

---

## ðŸŽ“ LeÃ§ons Apprises

### 1. Docker vs Compilation Native
**Conclusion:** Docker gagne 100x en temps/simplicitÃ©
- Native: Debugging system-specific issues (20+ heures)
- Docker: Reproductible, isolÃ© (30 min build)

### 2. DÃ©pendances Python
**Conclusion:** Jamais deviner, toujours consulter officiel
- Source de vÃ©ritÃ©: `pyproject.toml` du projet
- NumPy NOT required (indirect via torch)
- xformers = optimization (installation peut Ã©chouer, fallback OK)

### 3. Protocol WebSocket
**Conclusion:** Message ordering critique
- Eos = End-of-Stream signal (pattern streaming)
- Ready = Acknowledgement (peut ignorer)
- Audio = Chunks (peut Ãªtre multiple)

### 4. Concurrency Limits
**Conclusion:** Config nÃ©cessaire pas automatique
- Default: 4 workers (limitÃ©)
- Production: Augmenter Ã  16-32
- Scaling: Load balancer + multi-serveur

### 5. Performance Metrics
- **TTFA stable:** 250-280ms (peu dÃ©pend du texte)
- **RTF stable:** 0.44x (processing 2.26x temps rÃ©el)
- **Concurrency:** 5 clients OK sans dÃ©gradation

---

## ðŸ”— Ressources Officielles

```
GitHub Issues:
- https://github.com/kyutai-labs/moshi/issues
- https://github.com/kyutai-labs/delayed-streams-modeling/issues

Documentation:
- Moshi README: https://github.com/kyutai-labs/moshi/blob/master/README.md
- Rust Implementation: https://github.com/kyutai-labs/moshi/tree/master/rust
- Protocol Details: https://github.com/kyutai-labs/moshi/blob/master/rust/protocol.md

Models:
- HuggingFace TTS: https://huggingface.co/kyutai/tts-1.6b-en_fr
- HuggingFace Voices: https://huggingface.co/kyutai/tts-voices
```

---

**Document Version:** 1.0
**DerniÃ¨re mise Ã  jour:** 2025-01-21
**Statut:** Complete avec solutions testÃ©es âœ…
